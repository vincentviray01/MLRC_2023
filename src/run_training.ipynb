{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5489797f-2019-4e84-8a22-1561dbbc6160",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prevent random files being included in dataset\n",
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a660a9bf-733c-4920-bb64-5967b1dbbfe7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import mlflow\n",
    "import torch\n",
    "from utils import md5_dir, set_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# tqdm = partial(tqdm, position = 0, leave = True)\n",
    "\n",
    "from loss_functions import kd_loss\n",
    "from datasets import TrainImageNetDataset\n",
    "\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# if using pretrained model\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119e34ef-c30b-4e73-a51d-3a4c2dd23e65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4070927e-d82c-44d9-8841-0bd757d1477d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Default Parameters\n",
    "run_id = \"f13020b4e2304bd7837e10d17c6ea8ea\"\n",
    "train_data_path = \"../data/ImageNet/ILSVRC/Data/CLS-LOC/train/\"\n",
    "# test_data_path = \"data/ImageNet/ILSVRC/Data/CLS-LOC/val/\"\n",
    "\n",
    "train_data_labels_path = \"../data/ImageNet/LOC_train_solution.csv\"\n",
    "# test_data_labels_path = \"data/ImageNet/LOC_val_solution.csv\"\n",
    "\n",
    "label_mapping_path = \"../data/ImageNet/LOC_synset_mapping.txt\"\n",
    "\n",
    "resnet50_weights = ResNet50_Weights.DEFAULT\n",
    "\n",
    "preprocess = resnet50_weights.transforms()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e566e6-0761-4617-81fb-5d2e46471516",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainImageNetDataset(train_data_path, train_data_labels_path, label_mapping_path, preprocess, data_reduction = 0)\n",
    "\n",
    "# test_dataset = TestImageNetDataset(test_data_path, test_data_labels_path, label_mapping_path, preprocess)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=80, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2acf8f8a-046e-40f6-a3e9-e37523d53688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using pretrained model\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet18\n",
    "\n",
    "resnet50_pretrained_weights = ResNet50_Weights.DEFAULT\n",
    "\n",
    "epochs = 6\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b69b366-fa31-45fe-ad04-00905922251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__pycache__',\n",
       " 'run_experiment.ipynb',\n",
       " 'datasets.py',\n",
       " 'utils.py',\n",
       " 'output',\n",
       " 'run_preprocessing.ipynb',\n",
       " 'run_evaluation.ipynb',\n",
       " 'run_training.ipynb',\n",
       " 'mlruns',\n",
       " 'test.txt',\n",
       " 'mdoel_cherckpionts',\n",
       " '.ipynb_checkpoints',\n",
       " 'environment.txt',\n",
       " 'loss_functions.py']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e0ef45c-94b4-42b7-9a60-ab54368093d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 1/16015 [00:00<2:52:05,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.660658836364746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 2/16015 [00:01<2:54:02,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.621598243713379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 3/16015 [00:01<2:43:27,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47307825088501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 4/16015 [00:02<2:40:59,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.615926742553711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 5/16015 [00:03<2:36:36,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51435661315918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 6/16015 [00:03<2:34:13,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.277093887329102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 7/16015 [00:04<2:33:29,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.480215549468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 8/16015 [00:04<2:37:20,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.319109916687012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 9/16015 [00:05<2:34:59,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.301661491394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 10/16015 [00:05<2:37:03,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.417448043823242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 11/16015 [00:06<2:43:24,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.419055938720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 12/16015 [00:07<2:41:32,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.527471542358398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 13/16015 [00:07<2:40:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4186296463012695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 14/16015 [00:08<2:38:10,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.379304885864258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 14/16015 [00:09<2:52:36,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38444709777832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_student(student, teacher, train_dataloader, criterion, optimizer, epochs, device, model_save_path):\n",
    "    \"\"\"\n",
    "    - student: The smaller, untrained model that uses the teacher's output as an additional label\n",
    "    - teacher: The pretrained model used to help the student model learn\n",
    "    - train_dataloader: Dataloader for training data\n",
    "    - criterion: The loss function\n",
    "    - optimizer: The optimization algorithm\n",
    "    - epochs: Number of training epochs\n",
    "    - device: Device to run training\n",
    "    \"\"\"\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    student.train()\n",
    "    student.to(device)\n",
    "    epoch_print = 6000\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        loss_cntr = 0\n",
    "        previous_loss = 0.0\n",
    "\n",
    "        for inputs, labels in tqdm(train_dataloader, position = 0, leave = True):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = F.one_hot(labels, num_classes=1000).float()\n",
    "\n",
    "            # Zero the gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            teacher_predictions = teacher(inputs)\n",
    "            student_predictions = student(inputs)\n",
    "\n",
    "            loss = criterion(student_predictions, labels, teacher_predictions, 0.5, 0.5)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            previous_loss += loss\n",
    "            if loss_cntr > 0 and loss_cntr % epoch_print == 0:\n",
    "                print(\"Current loss:\", loss)\n",
    "                print(\"Running loss:\", running_loss)\n",
    "                print(\"Loss delta:\", previous_loss - loss)\n",
    "                print(\"Avg loss per epoch\", previous_loss/epoch_print)\n",
    "                previous_loss = 0.0\n",
    "            loss_cntr += 1\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            print(loss.item())\n",
    "            if epoch == 0 and loss_cntr == 15:\n",
    "                if model_save_path:\n",
    "                    torch.save(student.state_dict(), model_save_path)\n",
    "                return\n",
    "\n",
    "        average_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "        with mlflow.start_run(run_id=run_id) as run:\n",
    "            mlflow.log_metric(\"student_training_loss\", average_loss)\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id) as run:\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=teacher.to(\"cpu\"),\n",
    "            artifact_path=\"teacher\",)\n",
    "\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=student.to(\"cpu\"),\n",
    "            artifact_path=\"student\")\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet18\n",
    "\n",
    "resnet50_pretrained_weights = ResNet50_Weights.DEFAULT\n",
    "\n",
    "teacher = resnet50(weights=resnet50_pretrained_weights)\n",
    "\n",
    "\n",
    "student = resnet18(weights=None)\n",
    "pathh = \"03_19_034125\"\n",
    "model_load_path = \"./mdoel_cherckpionts/\" + pathh\n",
    "if model_load_path:\n",
    "    student.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr = 0.001)\n",
    "epochs = 6\n",
    "\n",
    "current_time = datetime.datetime.now().strftime('%m_%d_%H%M%S')\n",
    "model_save_path = \"./mdoel_cherckpionts/\" + current_time\n",
    "\n",
    "train_student(student, teacher, train_dataloader, kd_loss, optimizer, epochs, device, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438bdb3c-8fa6-4eef-b15d-e28cb6dca8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████▉                           | 4000/16015 [43:13<2:10:09,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(7.0426, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Loss delta: tensor(7.0426, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████▉                           | 4001/16015 [43:13<2:10:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(4.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss delta: tensor(-2.6484, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████▉                 | 8000/16015 [1:26:13<1:28:18,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(7.1135, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Loss delta: tensor(2.7193, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████▉                 | 8001/16015 [1:26:14<1:26:25,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(4.3814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss delta: tensor(-2.7321, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████▏        | 12000/16015 [2:09:34<44:21,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(6.9600, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Loss delta: tensor(2.5785, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████▏        | 12001/16015 [2:09:34<45:22,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(4.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss delta: tensor(-2.4916, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████▉| 16000/16015 [2:52:51<00:09,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(7.0803, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "Loss delta: tensor(2.6120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████▉| 16001/16015 [2:52:52<00:08,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "Current loss: tensor(4.5043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss delta: tensor(-2.5760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Avg loss per epoch tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 16015/16015 [2:53:01<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], independent_student: 7.0242\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Run '5363b9a6f6954354b7bb68d535b5ea88' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     13\u001b[0m std_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m components \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     ind_name: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: independent_student, \n\u001b[1;32m     17\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m\"\u001b[39m: ind_optimizer, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m               }\n\u001b[1;32m     28\u001b[0m }\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# train_student(student, teacher, train_dataloader, kd_loss, optimizer, epochs, device)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# train_independent_student(independent_student, train_dataloader, criterion, optimizer, epochs, device)\u001b[39;00m\n",
      "File \u001b[0;32m/home/src/utils.py:157\u001b[0m, in \u001b[0;36mtrain_models\u001b[0;34m(components, teacher, train_dataloader, epochs, device, run_id)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;66;03m# save training loss in mlflow\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m    158\u001b[0m             mlflow\u001b[38;5;241m.\u001b[39mlog_metric(student, avg_loss)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_id\u001b[38;5;241m=\u001b[39mrun_id) \u001b[38;5;28;01mas\u001b[39;00m run:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlrc_2023/lib/python3.11/site-packages/mlflow/tracking/fluent.py:315\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m existing_run_id:\n\u001b[1;32m    314\u001b[0m     _validate_run_id(existing_run_id)\n\u001b[0;32m--> 315\u001b[0m     active_run_obj \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_run_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# Check to see if experiment_id from environment matches experiment_id from set_experiment()\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    318\u001b[0m         _active_experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m _active_experiment_id \u001b[38;5;241m!=\u001b[39m active_run_obj\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mexperiment_id\n\u001b[1;32m    320\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/mlrc_2023/lib/python3.11/site-packages/mlflow/tracking/client.py:172\u001b[0m, in \u001b[0;36mMlflowClient.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlrc_2023/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:73\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mFetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mcontains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m         raises an exception.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlrc_2023/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:659\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03mNote: Will get both active and deleted runs.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    658\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m--> 659\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m metadata is in invalid state.\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mINVALID_STATE\n\u001b[1;32m    663\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlrc_2023/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:683\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[0;34m(self, run_uuid)\u001b[0m\n\u001b[1;32m    681\u001b[0m exp_id, run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_run_root(run_uuid)\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info_from_dir(run_dir)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "\u001b[0;31mMlflowException\u001b[0m: Run '5363b9a6f6954354b7bb68d535b5ea88' not found"
     ]
    }
   ],
   "source": [
    "teacher = resnet50(weights=resnet50_pretrained_weights)\n",
    "student = resnet18(weights=None)\n",
    "independent_student = resnet18(weights=None)\n",
    "\n",
    "\n",
    "ind_optimizer = torch.optim.Adam(student.parameters(), lr)\n",
    "optimizer = torch.optim.Adam(independent_student.parameters(), lr)\n",
    "\n",
    "ind_criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = kd_loss\n",
    "\n",
    "ind_name = \"independent_student\"\n",
    "std_name = \"student\"\n",
    "\n",
    "components = {\n",
    "    ind_name: {\"model\": independent_student, \n",
    "               \"opt\": ind_optimizer, \n",
    "               \"criterion\": ind_criterion, \n",
    "               \"running_loss\": 0,\n",
    "               \"previous_loss\": 0.0\n",
    "              },\n",
    "    std_name: {\"model\": student, \n",
    "               \"opt\": optimizer, \n",
    "               \"criterion\": criterion,\n",
    "               \"running_loss\": 0,\n",
    "               \"previous_loss\": 0.0\n",
    "              }\n",
    "}\n",
    "\n",
    "train_models(components, teacher, train_dataloader, epochs, device, run_id)\n",
    "# train_student(student, teacher, train_dataloader, kd_loss, optimizer, epochs, device)\n",
    "# train_independent_student(independent_student, train_dataloader, criterion, optimizer, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4a8aaa-36c7-44da-97bc-0249d381983a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 67\u001b[0m\n\u001b[1;32m     58\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mpytorch\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[1;32m     59\u001b[0m             pytorch_model\u001b[38;5;241m=\u001b[39mteacher\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     60\u001b[0m             artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m     62\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mpytorch\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[1;32m     63\u001b[0m             pytorch_model\u001b[38;5;241m=\u001b[39mstudent\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     64\u001b[0m             artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(student\u001b[38;5;241m.\u001b[39mparameters(), lr)\n\u001b[1;32m     68\u001b[0m train_student(student, teacher, train_dataloader, kd_loss, optimizer, epochs, device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def train_student(student, teacher, train_dataloader, criterion, optimizer, epochs, device):\n",
    "    \"\"\"\n",
    "    - student: The smaller, untrained model that uses the teacher's output as an additional label\n",
    "    - teacher: The pretrained model used to help the student model learn\n",
    "    - train_dataloader: Dataloader for training data\n",
    "    - criterion: The loss function\n",
    "    - optimizer: The optimization algorithm\n",
    "    - epochs: Number of training epochs\n",
    "    - device: Device to run training\n",
    "    \"\"\"\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    student.train()\n",
    "    student.to(device)\n",
    "\n",
    "    # with tqdm as epoch:\n",
    "        # for i in tqdm(range(epochs)):\n",
    "    # for epoch in tqdm(range(epochs), leave = True, position = 0):\n",
    "    # in tqdm(train_dataloader, leave = True, position = 0):\n",
    "    for epoch in tqdm(range(epochs), leave = True, position = 0):\n",
    "        running_loss = 0.0\n",
    "        sampleNum = 0\n",
    "        currentLoss = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_dataloader, leave = True, position = 0):\n",
    "        # for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = F.one_hot(labels, num_classes=1000).float()\n",
    "\n",
    "            # Zero the gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            teacher_predictions = teacher(inputs)\n",
    "            student_predictions = student(inputs)\n",
    "\n",
    "            loss = criterion(student_predictions, labels, teacher_predictions, 0.5, 0.5)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            currentLoss += loss.item()\n",
    "\n",
    "            # if sampleNum % 100 == 0 and sampleNum > 0: # write this to a file somewhere else so tqdm doesnt mess up\n",
    "            #     print(\"loss: \", str(currentLoss/100))\n",
    "            #     print(\"total loss: \", str(running_loss/sampleNum))\n",
    "            #     currentLoss = 0\n",
    "            sampleNum += 1\n",
    "            # print(str(running_loss) + \" \", end = '')\n",
    "            # break\n",
    "\n",
    "        average_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "        # save training loss in mlflow\n",
    "        with mlflow.start_run(run_id=run_id) as run:\n",
    "            mlflow.log_metric(\"student_training_loss\", average_loss)\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id) as run:\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=teacher.to(\"cpu\"),\n",
    "            artifact_path=\"teacher\",)\n",
    "\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=student.to(\"cpu\"),\n",
    "            artifact_path=\"student\")\n",
    "        \n",
    "\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr)\n",
    "train_student(student, teacher, train_dataloader, kd_loss, optimizer, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53f83e-fe4e-4569-8bd9-ab130941f7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2188d05a-f37c-4cf3-a3cb-749d0758355d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'tqdm' has no attribute 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(independent_student\u001b[38;5;241m.\u001b[39mparameters(), lr)\n\u001b[1;32m     49\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrain_independent_student\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindependent_student\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mtrain_independent_student\u001b[0;34m(independent_student, train_dataloader, criterion, optimizer, epochs, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m independent_student\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     11\u001b[0m independent_student\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m     14\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_dataloader):\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'tqdm' has no attribute 'tqdm'"
     ]
    }
   ],
   "source": [
    "def train_independent_student(independent_student, train_dataloader, criterion, optimizer, epochs, device):\n",
    "    \"\"\"\n",
    "    - teacher: The pretrained model used to help the student model learn\n",
    "    - student: The smaller, untrained model that uses the teacher's output as an additional label\n",
    "    - criterion: The loss function\n",
    "    - optimizer: The optimization algorithm\n",
    "    - epochs: Number of training epochs\n",
    "    - device: Device to run training\n",
    "    \"\"\"\n",
    "    independent_student.train()\n",
    "    independent_student.to(device)\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in tqdm(train_dataloader, leave = True, position = 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = F.one_hot(labels, num_classes=1000).float()\n",
    "\n",
    "            # Zero the gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            independent_student_predictions = independent_student(inputs)\n",
    "\n",
    "            loss = criterion(independent_student_predictions, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            break\n",
    "\n",
    "        average_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "\n",
    "        # save training loss in mlflow\n",
    "        with mlflow.start_run(run_id=run_id) as run:\n",
    "            mlflow.log_metric(\"independent_student_training_loss\", average_loss)\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id) as run:\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=independent_student.to(\"cpu\"),\n",
    "            artifact_path=\"independent_student\"\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.Adam(independent_student.parameters(), lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_independent_student(independent_student, train_dataloader, criterion, optimizer, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e1e1a-279b-4266-bfd1-8be9dca52d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfc7e6-ee6b-4c41-871c-63d6e95e2c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
